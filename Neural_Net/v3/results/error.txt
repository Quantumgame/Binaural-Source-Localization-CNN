2017-12-06 11:18:20.465299: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 11:18:20.465473: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 11:18:20.466234: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 11:18:20.466260: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 11:18:20.466268: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 11:18:31.803950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:08:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-06 11:18:32.096094: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x55b4e8c724a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-06 11:18:32.097033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:09:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-06 11:18:32.401440: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x55b4e8c76500 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-06 11:18:32.402404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:88:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-06 11:18:32.710295: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x55b4ea7c12b0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-12-06 11:18:32.711331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:89:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-06 11:18:32.711637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-12-06 11:18:32.711665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-12-06 11:18:32.711695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-12-06 11:18:32.711712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-12-06 11:18:32.711728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-12-06 11:18:32.711744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-12-06 11:18:32.711974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-12-06 11:18:32.711996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-12-06 11:18:32.712067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-12-06 11:18:32.712103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y N N 
2017-12-06 11:18:32.712116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y N N 
2017-12-06 11:18:32.712124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y Y 
2017-12-06 11:18:32.712132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N Y Y 
2017-12-06 11:18:32.712159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:08:00.0)
2017-12-06 11:18:32.712173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:09:00.0)
2017-12-06 11:18:32.712182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:88:00.0)
2017-12-06 11:18:32.712190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:89:00.0)
Using TensorFlow backend.
neuralnet.py:76: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.
  verbose=2)
neuralnet.py:76: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(verbose=2, generator=<generator..., validation_data=<generator..., steps_per_epoch=10144, epochs=20, validation_steps=2536)`
  verbose=2)
2017-12-06 11:19:13.698862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:08:00.0)
2017-12-06 11:19:13.698916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:09:00.0)
2017-12-06 11:19:13.698932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:88:00.0)
2017-12-06 11:19:13.698943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:89:00.0)
slurmstepd: error: *** JOB 1676364 ON bhg0034 CANCELLED AT 2017-12-06T15:18:04 DUE TO TIME LIMIT ***
